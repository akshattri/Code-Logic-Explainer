{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mounting Google Drive**"
      ],
      "metadata": {
        "id": "wlnj9g9M3f3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5y6yhBP85Lb",
        "outputId": "5b2f511e-c788-42c4-c45a-91c782a37a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with automatic authorization\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using GPU**"
      ],
      "metadata": {
        "id": "5BIZxsrb3q1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQVwsqL995xa",
        "outputId": "bc864520-a4c2-4ce8-ba5f-bc09e96dbbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6GE7TBh9CVE",
        "outputId": "7038a142-f4c1-437c-8cd3-a7187af5690c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading of dataset and creating a vocabulary in a code-related context**"
      ],
      "metadata": {
        "id": "selofEBTAB5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from io import open\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "\n",
        "class CodeVocabulary:\n",
        "    def __init__(self):\n",
        "        self.token2index = {\"<s>\": 0, \"</s>\": 1}\n",
        "        self.index2token = {0: \"<s>\", 1: \"</s>\"}\n",
        "        self.n_tokens = 2\n",
        "\n",
        "    def getIndex(self, token):\n",
        "        if token not in self.token2index:\n",
        "            self.token2index[token] = self.n_tokens\n",
        "            self.index2token[self.n_tokens] = token\n",
        "            self.n_tokens += 1\n",
        "        return self.token2index[token]\n",
        "\n",
        "def tokenizeCode(code):\n",
        "    tokens = []\n",
        "    for tok in tokenize.tokenize(BytesIO(code.encode('utf-8')).readline):\n",
        "        if tok.type == tokenize.NAME or tok.type == tokenize.OP:\n",
        "            tokens.append(tok.string)\n",
        "    return tokens\n",
        "\n",
        "def normalizeCode(code):\n",
        "    tokens = tokenizeCode(code)\n",
        "    normalized_code = ' '.join(tokens)\n",
        "    return normalized_code\n",
        "\n",
        "def readCodeCorpus(file, num_lines=50000):\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()[:num_lines]\n",
        "\n",
        "    data = [json.loads(line) for line in lines]\n",
        "    code_corpus = [\"<s> \" + normalizeCode(item[\"snippet\"]) + \" </s>\" for item in data]\n",
        "\n",
        "    # Extract intents and encode them using LabelEncoder\n",
        "    intents = [item[\"intent\"] for item in data]\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_intents = label_encoder.fit_transform(intents)\n",
        "\n",
        "    return code_corpus, encoded_intents\n",
        "\n",
        "def readCodeCorpus_json(file):\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    code_corpus = [\"<s> \" + normalizeCode(item[\"snippet\"].split()) + \" </s>\" for item in data]\n",
        "\n",
        "    # Extract intents and encode them using LabelEncoder\n",
        "    intents = [item[\"intent\"] for item in data]\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_intents = label_encoder.fit_transform(intents)\n",
        "\n",
        "    return code_corpus, encoded_intents\n",
        "\n",
        "# Usage\n",
        "code_file_path = \"/content/drive/MyDrive/conala-mined.jsonl\"\n",
        "code_vocab = CodeVocabulary()\n",
        "code_corpus, encoded_intents = readCodeCorpus(code_file_path, num_lines=50000)\n",
        "code_numbered_corpus = [[code_vocab.getIndex(token) for token in code.split(' ')] for code in code_corpus]\n",
        "\n",
        "\n",
        "# test_file_path = \"/content/drive/MyDrive/conala-test.json\"\n",
        "# test_code_corpus, test_intents = readCodeCorpus_json(test_file_path)\n",
        "# test_numbered_corpus = [[code_vocab.getIndex(token) for token in code.split(' ')] for code in test_code_corpus]"
      ],
      "metadata": {
        "id": "1foFCS9h9V-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining an RNN model using GRU taking reference from a machine translation task**"
      ],
      "metadata": {
        "id": "2lDRtXWvCmCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# similarity_threshold = 0.05\n",
        "class CodeRNN(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, output_size):\n",
        "        super(CodeRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, hidden_size)\n",
        "        self.gru = torch.nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self, device):\n",
        "        return torch.zeros(1, 1, self.hidden_size).to(device)\n",
        "\n",
        "def trainCodeModel(vocab, numbered_corpus, intents, hidden_size=256, learning_rate=0.01, n_epochs=30, device=device):\n",
        "    code_rnn = CodeRNN(vocab.n_tokens, hidden_size, len(set(intents))).to(device)\n",
        "    optimizer = torch.optim.SGD(code_rnn.parameters(), lr=learning_rate)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for code_sequence, intent in zip(numbered_corpus, intents):\n",
        "            optimizer.zero_grad()\n",
        "            code_loss = 0\n",
        "            hidden = code_rnn.initHidden(device)\n",
        "\n",
        "            # Include intent information in the forward pass\n",
        "            for i in range(len(code_sequence) - 1):\n",
        "                input_tensor = torch.tensor([[code_sequence[i]]]).to(device)\n",
        "                output, hidden = code_rnn.forward(input_tensor, hidden)\n",
        "                target_tensor = torch.tensor([code_sequence[i + 1]]).view(-1).to(device)\n",
        "\n",
        "            # Include intent information in the loss calculation\n",
        "            intent_tensor = torch.tensor([intent]).view(-1).to(device)\n",
        "            intent_loss = criterion(output, intent_tensor)\n",
        "            code_loss += intent_loss\n",
        "\n",
        "            total_loss += code_loss.data.item()\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total_predictions += 1\n",
        "            correct_predictions += (predicted == intent_tensor).sum().item()\n",
        "\n",
        "            code_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(numbered_corpus)}, Train Accuracy: {accuracy}\")\n",
        "\n",
        "    return code_rnn\n",
        "\n",
        "# Example usage:\n",
        "trained_code_model = trainCodeModel(code_vocab, code_numbered_corpus, encoded_intents)"
      ],
      "metadata": {
        "id": "QLr4yYY6I73S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b84c10-d8ff-4380-a6dd-917d54dfbb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 9.62987787319546, Train Accuracy: 0.0048\n",
            "Epoch 2, Loss: 8.822366762380302, Train Accuracy: 0.014733333333333333\n",
            "Epoch 3, Loss: 7.788806717820155, Train Accuracy: 0.038533333333333336\n",
            "Epoch 4, Loss: 6.642575925120774, Train Accuracy: 0.0823\n",
            "Epoch 5, Loss: 5.545598973507496, Train Accuracy: 0.1435\n",
            "Epoch 6, Loss: 4.563882820221036, Train Accuracy: 0.23246666666666665\n",
            "Epoch 7, Loss: 3.7094886477756623, Train Accuracy: 0.3364\n",
            "Epoch 8, Loss: 2.9854286018696303, Train Accuracy: 0.4395\n",
            "Epoch 9, Loss: 2.4027039745451884, Train Accuracy: 0.5349666666666667\n",
            "Epoch 10, Loss: 1.9612885263240585, Train Accuracy: 0.6151666666666666\n",
            "Epoch 11, Loss: 1.6421351078849906, Train Accuracy: 0.6697333333333333\n",
            "Epoch 12, Loss: 1.4089344823644807, Train Accuracy: 0.7149333333333333\n",
            "Epoch 13, Loss: 1.2344058115921295, Train Accuracy: 0.7483333333333333\n",
            "Epoch 14, Loss: 1.1033259812533078, Train Accuracy: 0.7736333333333333\n",
            "Epoch 15, Loss: 1.006251284126239, Train Accuracy: 0.7909\n",
            "Epoch 16, Loss: 0.9257607717891224, Train Accuracy: 0.8030333333333334\n",
            "Epoch 17, Loss: 0.8614917371242851, Train Accuracy: 0.814\n",
            "Epoch 18, Loss: 0.8098801664103754, Train Accuracy: 0.8216\n",
            "Epoch 19, Loss: 0.7653914762351894, Train Accuracy: 0.8278\n",
            "Epoch 20, Loss: 0.7319582821495986, Train Accuracy: 0.8332666666666667\n",
            "Epoch 21, Loss: 0.7008796994711816, Train Accuracy: 0.8384666666666667\n",
            "Epoch 22, Loss: 0.6756375398253867, Train Accuracy: 0.8411666666666666\n",
            "Epoch 23, Loss: 0.6558736352457122, Train Accuracy: 0.8443666666666667\n",
            "Epoch 24, Loss: 0.6369367316865362, Train Accuracy: 0.8474\n",
            "Epoch 25, Loss: 0.6218001496242631, Train Accuracy: 0.8486333333333334\n",
            "Epoch 26, Loss: 0.6163416048661068, Train Accuracy: 0.8500333333333333\n",
            "Epoch 27, Loss: 0.5999206377716075, Train Accuracy: 0.8517666666666667\n",
            "Epoch 28, Loss: 0.5889976642768753, Train Accuracy: 0.8525666666666667\n",
            "Epoch 29, Loss: 0.5768968175679658, Train Accuracy: 0.8549333333333333\n",
            "Epoch 30, Loss: 0.5684818153100146, Train Accuracy: 0.8556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving the model for testing in real time**"
      ],
      "metadata": {
        "id": "JcNJNk59DRkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save the model\n",
        "model_save_path = \"/content/drive/MyDrive/vlg_model.pth\"\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(trained_code_model, model_save_path)\n",
        "\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "id": "gTwZrqQnzRKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Real Time Testing**"
      ],
      "metadata": {
        "id": "njsGamD3HbrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeRNN(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, output_size):\n",
        "        super(CodeRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, hidden_size)\n",
        "        self.gru = torch.nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self, device):\n",
        "        return torch.zeros(1, 1, self.hidden_size).to(device)\n",
        "\n",
        "def trainCodeModel(vocab, numbered_corpus, intents, hidden_size=256, learning_rate=0.01, n_epochs=30, device=device):\n",
        "    code_rnn = CodeRNN(vocab.n_tokens, hidden_size, len(set(intents))).to(device)\n",
        "    optimizer = torch.optim.SGD(code_rnn.parameters(), lr=learning_rate)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for code_sequence, intent in zip(numbered_corpus, intents):\n",
        "            optimizer.zero_grad()\n",
        "            code_loss = 0\n",
        "            hidden = code_rnn.initHidden(device)\n",
        "\n",
        "            # Include intent information in the forward pass\n",
        "            for i in range(len(code_sequence) - 1):\n",
        "                input_tensor = torch.tensor([[code_sequence[i]]]).to(device)\n",
        "                output, hidden = code_rnn.forward(input_tensor, hidden)\n",
        "                target_tensor = torch.tensor([code_sequence[i + 1]]).view(-1).to(device)\n",
        "\n",
        "            # Include intent information in the loss calculation\n",
        "            intent_tensor = torch.tensor([intent]).view(-1).to(device)\n",
        "            intent_loss = criterion(output, intent_tensor)\n",
        "            code_loss += intent_loss\n",
        "\n",
        "            total_loss += code_loss.data.item()\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total_predictions += 1\n",
        "            correct_predictions += (predicted == intent_tensor).sum().item()\n",
        "\n",
        "            code_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(numbered_corpus)}, Train Accuracy: {accuracy}\")\n",
        "\n",
        "    return code_rnn"
      ],
      "metadata": {
        "id": "C53SNv7GsfyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the trained model\n",
        "trained_code_model = torch.load(\"/content/drive/MyDrive/dsg_model_1.pth\")\n",
        "\n",
        "def predict_intent(code_snippet, model, vocab, device=device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Tokenize the code snippet and replace unknown tokens with \"<unk>\"\n",
        "        code_tokens = [token if token in vocab.token2index else \"<unk>\" for token in code_snippet.split(' ')]\n",
        "        code_sequence = [vocab.getIndex(token) for token in code_tokens]\n",
        "\n",
        "        hidden = model.initHidden(device)\n",
        "        output = None\n",
        "\n",
        "        for i in range(len(code_sequence) - 1):\n",
        "            input_tensor = torch.tensor([[code_sequence[i]]]).to(device)\n",
        "            output, hidden = model.forward(input_tensor, hidden, vocab)\n",
        "\n",
        "        if output is not None:\n",
        "            _, predicted_intent_index = torch.max(output, 1)\n",
        "            predicted_intent = vocab.index2token[predicted_intent_index.item()]\n",
        "        else:\n",
        "            predicted_intent = \"Unknown\"\n",
        "\n",
        "    return predicted_intent\n",
        "\n",
        "code_snippet = \"pd.get_dummies(df)\"\n",
        "predicted_intent = predict_intent(code_snippet, trained_code_model, code_vocab, device=device)\n",
        "print(f\"Predicted Intent: {predicted_intent}\")\n"
      ],
      "metadata": {
        "id": "vd9jC6g19CGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e70c79c-3457-4f7a-9a48-dd252d9cdbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Intent: Unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PCG0FSQis2TQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}